### 具体方案
#### 总体流程
> *特征的简单处理，然后对特征进行衍生，最后进行特征筛选，形成模型特征池*
#### 单变量处理
##### 时间戳类行处理
+ 拆分 年月日时分秒 为多个变量
+ 等等

##### 类别属性
+ 拆分为多个虚拟变量，例如男女，拆分为是否为男性，是否为女性

##### 连续变量的离散化
+ 分箱分区  例如 0-10 为一个是否变量， 100-200 为一个是否变量，划分的区间需要进一步讨论

##### 连续数值变量的平滑性处理
+ 根据某些平滑性处理方法决定是否取log

##### 异常数据的处理
+ 缺失值的补充
+ 离群值得删除

##### 类别变量不平衡性处理
+ 当分类的变量target属性不平衡时，进行欠采样或过采样


#### 特征衍生
> *特征衍生之前，首先对特征进行分类 ，数值特征、类别特征(是否),时间特征，即相同的特征进行后续的衍生操作*     
###### 数值类型的衍生
+ 数值类型的变量 衍生出多项式的变量 例如 （x1,x2）=> （x1,x2,x1*x1,x2*x2,x1*x2）  

> *此处需考虑衍生变量的个数，即2个变量一起进行衍生，或者3个变量一起进行衍生*

###### 类别类型的衍生(是否即0/1类型)
> *此处进行衍生的目的是为了获取如下的有效特征，例如 按照年年龄划分出了几个特征,即0-10岁 10-30岁 30-60岁 60-100岁，对0-10和10-30进行或运算 衍生出一个叫是否为青年人的变量*

+ 同一个组内的是否特征，进行或运算
+ 不同组内的是否特征，进行与运算

> *以上特征处理后会形成很多个特征，下面进行特征的筛选。特征筛选的主要思路为，采用不同的差选方法按照该方法对应的评分选出设置好个数的特征数量(这个数量可以按照上传数据的比例计算后默认设置)，然后进行取并集为后续模型的特征池*

#### 特征选择（以下选择方法在sklearn中基本都有对应的包支持）

##### 剔除方差过小的变量,按照排名保留固定数量的特征
> *方差太小意味着对label影响很小*
+  数值变量的方差
+  类别特征的方差

##### 进行卡方 F检验等，按照排名保留固定数量的特征
##### 利用循环特征剔除方法(RFE),按照评分保留一部分特征(使用lr作为中间模型)
##### 利用随机森林自带的评价特征重要性的参数，按照评分保留一部分模型
-----------
以上模型方法选出的变量，取并集形成后续的特征池。
